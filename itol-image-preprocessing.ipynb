{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:32:16.649273Z","iopub.execute_input":"2025-07-31T04:32:16.649441Z","iopub.status.idle":"2025-07-31T04:32:16.990778Z","shell.execute_reply.started":"2025-07-31T04:32:16.649425Z","shell.execute_reply":"2025-07-31T04:32:16.990153Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%capture\n%pip install --no-deps bitsandbytes accelerate xformers peft trl triton cut_cross_entropy unsloth_zoo\n%pip install sentencepiece protobuf datasets huggingface_hub hf_transfer nltk python-Levenshtein\n%pip install --no-deps unsloth\n%pip install -q albumentations opencv-python scikit-image\n%pip install -q torch torchvision torchaudio\n%pip install uncertainty-toolbox","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:32:42.317404Z","iopub.execute_input":"2025-07-31T04:32:42.318024Z","iopub.status.idle":"2025-07-31T04:34:25.255723Z","shell.execute_reply.started":"2025-07-31T04:32:42.317990Z","shell.execute_reply":"2025-07-31T04:34:25.254698Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from io import BytesIO\nimport base64\nfrom PIL import Image\nimport cv2\nimport numpy as np\nfrom datasets import load_dataset\nimport torch\nfrom unsloth import FastVisionModel\nfrom trl import SFTTrainer, SFTConfig\nfrom unsloth.trainer import UnslothVisionDataCollator\nfrom tqdm import tqdm\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu\nimport Levenshtein\nimport subprocess\nimport tempfile\nimport os\nfrom transformers import TextStreamer\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:52:54.333752Z","iopub.execute_input":"2025-07-31T04:52:54.334062Z","iopub.status.idle":"2025-07-31T04:52:54.341156Z","shell.execute_reply.started":"2025-07-31T04:52:54.334040Z","shell.execute_reply":"2025-07-31T04:52:54.340453Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"class ImagePreprocessor:\n    def __init__(self):\n        pass\n\n    def binarize_image(self, image: Image.Image, method='otsu') -> Image.Image:\n        gray = image.convert('L')\n        img_array = np.array(gray)\n        if method == 'otsu':\n            _, binary = cv2.threshold(img_array, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n        elif method == 'adaptive':\n            binary = cv2.adaptiveThreshold(img_array, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n                                        cv2.THRESH_BINARY, 11, 2)\n        return Image.fromarray(binary)\n    \n    def noise_filtering(self, image: Image.Image) -> Image.Image:\n        img_array = np.array(image)\n        filtered = cv2.medianBlur(img_array, 3)\n        kernel = np.ones((2, 2), np.uint8)\n        filtered = cv2.morphologyEx(filtered, cv2.MORPH_CLOSE, kernel)\n        filtered = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n        return Image.fromarray(filtered)\n    \n    def deskew_image(self, image: Image.Image) -> Image.Image:\n        img_array = np.array(image.convert('L'))\n        coords = np.column_stack(np.where(img_array > 0))\n        if len(coords) == 0:\n            return image\n        angle = cv2.minAreaRect(coords)[-1]\n        if angle < -45:\n            angle = -(90 + angle)\n        else:\n            angle = -angle\n        (h, w) = img_array.shape[:2]\n        center = (w // 2, h // 2)\n        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n        rotated = cv2.warpAffine(img_array, M, (w, h), flags=cv2.INTER_CUBIC, \n                               borderMode=cv2.BORDER_REPLICATE)\n        return Image.fromarray(rotated)\n    \n    def preprocess_image(self, image: Image.Image) -> Image.Image:\n        filtered_img = self.noise_filtering(image)\n        deskewed_img = self.deskew_image(filtered_img)\n        binary_img = self.binarize_image(deskewed_img)\n        return binary_img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:53:37.287438Z","iopub.execute_input":"2025-07-31T04:53:37.288264Z","iopub.status.idle":"2025-07-31T04:53:37.297698Z","shell.execute_reply.started":"2025-07-31T04:53:37.288236Z","shell.execute_reply":"2025-07-31T04:53:37.296871Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Image Encoding & Dataset Preprocessing","metadata":{}},{"cell_type":"code","source":"def pil_image_to_base64_str(img: Image.Image) -> str:\n    buffered = BytesIO()\n    img.save(buffered, format=\"PNG\")\n    img_b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n    return img_b64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:54:10.906284Z","iopub.execute_input":"2025-07-31T04:54:10.906553Z","iopub.status.idle":"2025-07-31T04:54:10.910817Z","shell.execute_reply.started":"2025-07-31T04:54:10.906534Z","shell.execute_reply":"2025-07-31T04:54:10.910137Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def base64_str_to_pil(img_b64: str) -> Image.Image:\n    img_bytes = base64.b64decode(img_b64)\n    return Image.open(BytesIO(img_bytes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:54:22.402046Z","iopub.execute_input":"2025-07-31T04:54:22.402324Z","iopub.status.idle":"2025-07-31T04:54:22.407114Z","shell.execute_reply.started":"2025-07-31T04:54:22.402303Z","shell.execute_reply":"2025-07-31T04:54:22.406089Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def preprocess_dataset(dataset, preprocessor):\n    \"\"\"Add a new column with preprocessed images encoded as base64 strings.\"\"\"\n    new_images_b64 = []\n    for sample in tqdm(dataset, desc=\"Preprocessing dataset\"):\n        image = sample[\"image\"]\n        preprocessed = preprocessor.preprocess_image(image)\n        img_b64 = pil_image_to_base64_str(preprocessed)\n        new_images_b64.append(img_b64)\n    return dataset.add_column(\"preprocessed_image\", new_images_b64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:54:28.080701Z","iopub.execute_input":"2025-07-31T04:54:28.081463Z","iopub.status.idle":"2025-07-31T04:54:28.085833Z","shell.execute_reply.started":"2025-07-31T04:54:28.081440Z","shell.execute_reply":"2025-07-31T04:54:28.085070Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Evaluation Functions","metadata":{}},{"cell_type":"code","source":"def exact_match_accuracy(predictions: list, targets: list) -> float:\n    matches = [pred.strip() == target.strip() for pred, target in zip(predictions, targets)]\n    return np.mean(matches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:54:49.542615Z","iopub.execute_input":"2025-07-31T04:54:49.543381Z","iopub.status.idle":"2025-07-31T04:54:49.547428Z","shell.execute_reply.started":"2025-07-31T04:54:49.543347Z","shell.execute_reply":"2025-07-31T04:54:49.546580Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def calculate_bleu_scores(predictions: list, targets: list) -> list:\n    bleu_scores = []\n    for pred, target in zip(predictions, targets):\n        pred_tokens = pred.strip().split()\n        target_tokens = target.strip().split()\n        if len(target_tokens) == 0:\n            bleu_scores.append(0.0)\n        else:\n            try:\n                score = sentence_bleu([target_tokens], pred_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n                bleu_scores.append(score)\n            except:\n                bleu_scores.append(0.0)\n    return bleu_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:55:08.163607Z","iopub.execute_input":"2025-07-31T04:55:08.164001Z","iopub.status.idle":"2025-07-31T04:55:08.170208Z","shell.execute_reply.started":"2025-07-31T04:55:08.163973Z","shell.execute_reply":"2025-07-31T04:55:08.168848Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def calculate_edit_distances(predictions: list, targets: list) -> list:\n    return [Levenshtein.distance(p.strip(), t.strip()) for p, t in zip(predictions, targets)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:55:23.755282Z","iopub.execute_input":"2025-07-31T04:55:23.755602Z","iopub.status.idle":"2025-07-31T04:55:23.761001Z","shell.execute_reply.started":"2025-07-31T04:55:23.755577Z","shell.execute_reply":"2025-07-31T04:55:23.759979Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def check_latex_compilation(latex_code: str) -> bool:\n    latex_document = f\"\"\"\n    \\\\documentclass{{article}}\n    \\\\usepackage{{amsmath, amssymb, amsfonts}}\n    \\\\begin{{document}}\n    $${latex_code}$$\n    \\\\end{{document}}\n    \"\"\"\n    try:\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.tex', delete=False) as f:\n            f.write(latex_document)\n            tex_file = f.name\n        result = subprocess.run(['pdflatex', '-interaction=nonstopmode', tex_file], \n                              capture_output=True, timeout=10, cwd='/tmp')\n        base_name = tex_file[:-4]\n        for ext in ['.tex', '.pdf', '.log', '.aux']:\n            try:\n                os.unlink(base_name + ext)\n            except:\n                pass\n        return result.returncode == 0\n    except Exception as e:\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:55:37.152513Z","iopub.execute_input":"2025-07-31T04:55:37.152799Z","iopub.status.idle":"2025-07-31T04:55:37.158449Z","shell.execute_reply.started":"2025-07-31T04:55:37.152777Z","shell.execute_reply":"2025-07-31T04:55:37.157697Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def compilation_success_rate(predictions: list) -> float:\n    success_count = sum(check_latex_compilation(pred) for pred in predictions)\n    return success_count / len(predictions) if len(predictions) > 0 else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:55:46.736736Z","iopub.execute_input":"2025-07-31T04:55:46.737365Z","iopub.status.idle":"2025-07-31T04:55:46.741660Z","shell.execute_reply.started":"2025-07-31T04:55:46.737339Z","shell.execute_reply":"2025-07-31T04:55:46.740948Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def analyze_errors(predictions: list, targets: list, top_k=5):\n    errors = []\n    for pred, target in zip(predictions, targets):\n        if pred.strip() != target.strip():\n            errors.append({\n                'prediction': pred,\n                'target': target,\n                'edit_distance': Levenshtein.distance(pred, target)\n            })\n    errors.sort(key=lambda x: x['edit_distance'], reverse=True)\n    print(f\"\\nTop {top_k} most different predictions:\")\n    for i, error in enumerate(errors[:top_k]):\n        print(f\"{i+1}. Edit distance: {error['edit_distance']}\")\n        print(f\"   Target: {error['target']}\")\n        print(f\"   Prediction: {error['prediction']}\\n\")\n    return errors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:55:56.704631Z","iopub.execute_input":"2025-07-31T04:55:56.705104Z","iopub.status.idle":"2025-07-31T04:55:56.711640Z","shell.execute_reply.started":"2025-07-31T04:55:56.705077Z","shell.execute_reply":"2025-07-31T04:55:56.710695Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def convert_to_conversation(sample, instruction=\"Write the LaTeX representation for this image.\"):\n    conversation = [\n        {\"role\": \"user\", \"content\": [\n            {\"type\": \"text\", \"text\": instruction},\n            {\"type\": \"image\", \"image\": sample[\"image\"]}\n        ]},\n        {\"role\": \"assistant\", \"content\": [\n            {\"type\": \"text\", \"text\": sample[\"text\"]}\n        ]}\n    ]\n    return {\"messages\": conversation}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T04:56:15.296786Z","iopub.execute_input":"2025-07-31T04:56:15.297708Z","iopub.status.idle":"2025-07-31T04:56:15.303683Z","shell.execute_reply.started":"2025-07-31T04:56:15.297671Z","shell.execute_reply":"2025-07-31T04:56:15.302906Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## Model Eval Function","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, tokenizer, eval_dataset, image_col=\"image\", max_samples=None):\n    \"\"\"Evaluate model on dataset supporting both PIL images and base64 strings.\"\"\"\n    model.eval()\n    predictions, targets = [], []\n    samples = eval_dataset if max_samples is None else eval_dataset.select(range(min(max_samples, len(eval_dataset))))\n    instruction = \"Write the LaTeX representation for this image.\"\n    for sample in samples:\n        img_data = sample[image_col]\n        # Determine if the image is a PIL image or a base64 string\n        if isinstance(img_data, Image.Image):\n            img = img_data\n        elif isinstance(img_data, str):\n            img = base64_str_to_pil(img_data)\n        else:\n            raise TypeError(f\"Unsupported type for image: {type(img_data)}\")\n        \n        messages = [\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"text\", \"text\": instruction},\n                {\"type\": \"image\", \"image\": img}\n            ]}\n        ]\n        input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n        inputs = tokenizer(\n            img, input_text,\n            add_special_tokens=False,\n            return_tensors=\"pt\",\n        ).to(\"cuda\")\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs, \n                max_new_tokens=128, \n                use_cache=True, \n                temperature=0.1, \n                pad_token_id=tokenizer.eos_token_id\n            )\n        prediction = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True).strip()\n        predictions.append(prediction)\n        targets.append(sample[\"text\"])\n    exact_match = exact_match_accuracy(predictions, targets)\n    bleu_scores = calculate_bleu_scores(predictions, targets)\n    edit_distances = calculate_edit_distances(predictions, targets)\n    compilation_rate = compilation_success_rate(predictions)\n    metrics = {\n        \"exact_match_accuracy\": exact_match,\n        \"average_bleu\": np.mean(bleu_scores),\n        \"median_bleu\": np.median(bleu_scores),\n        \"std_bleu\": np.std(bleu_scores),\n        \"average_edit_distance\": np.mean(edit_distances),\n        \"median_edit_distance\": np.median(edit_distances),\n        \"std_edit_distance\": np.std(edit_distances),\n        \"compilation_success_rate\": compilation_rate,\n        \"num_samples\": len(predictions)\n    }\n    return metrics, predictions, targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:02:28.689133Z","iopub.execute_input":"2025-07-31T05:02:28.689454Z","iopub.status.idle":"2025-07-31T05:02:28.698966Z","shell.execute_reply.started":"2025-07-31T05:02:28.689431Z","shell.execute_reply":"2025-07-31T05:02:28.698256Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"from PIL import Image\nimport io\n\ndef load_and_convert_to_pil(path_or_bytes):\n    if isinstance(path_or_bytes, bytes):\n        return Image.open(io.BytesIO(path_or_bytes))\n    else:\n        return Image.open(path_or_bytes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:00:53.497594Z","iopub.execute_input":"2025-07-31T05:00:53.497851Z","iopub.status.idle":"2025-07-31T05:00:53.502033Z","shell.execute_reply.started":"2025-07-31T05:00:53.497834Z","shell.execute_reply":"2025-07-31T05:00:53.501206Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"dataset = load_dataset(\"unsloth/Latex_OCR\", split=\"train[:500]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:04:29.051183Z","iopub.execute_input":"2025-07-31T05:04:29.051956Z","iopub.status.idle":"2025-07-31T05:04:30.812598Z","shell.execute_reply.started":"2025-07-31T05:04:29.051928Z","shell.execute_reply":"2025-07-31T05:04:30.812032Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# dataset = dataset.map(lambda x: {\"image\": load_and_convert_to_pil(x[\"image\"])}, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:02:44.172663Z","iopub.execute_input":"2025-07-31T05:02:44.172962Z","iopub.status.idle":"2025-07-31T05:02:44.176545Z","shell.execute_reply.started":"2025-07-31T05:02:44.172940Z","shell.execute_reply":"2025-07-31T05:02:44.175937Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"split_data = dataset.train_test_split(test_size=0.2, seed=42)\ntrain_dataset = split_data[\"train\"]\ntemp_dataset = split_data[\"test\"]\neval_test_split = temp_dataset.train_test_split(test_size=0.5, seed=42)\neval_dataset = eval_test_split[\"train\"]\ntest_dataset = eval_test_split[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:04:34.303101Z","iopub.execute_input":"2025-07-31T05:04:34.303355Z","iopub.status.idle":"2025-07-31T05:04:34.346179Z","shell.execute_reply.started":"2025-07-31T05:04:34.303336Z","shell.execute_reply":"2025-07-31T05:04:34.345603Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"preprocessor = ImagePreprocessor()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:04:36.812070Z","iopub.execute_input":"2025-07-31T05:04:36.812319Z","iopub.status.idle":"2025-07-31T05:04:36.815886Z","shell.execute_reply.started":"2025-07-31T05:04:36.812302Z","shell.execute_reply":"2025-07-31T05:04:36.815301Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Step 3: Preprocess validation and test datasets\neval_dataset = preprocess_dataset(eval_dataset, preprocessor)  # Adds \"preprocessed_image\" column\ntest_dataset = preprocess_dataset(test_dataset, preprocessor)   # Adds \"preprocessed_image\" column","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:04:40.503311Z","iopub.execute_input":"2025-07-31T05:04:40.503583Z","iopub.status.idle":"2025-07-31T05:04:40.810372Z","shell.execute_reply.started":"2025-07-31T05:04:40.503562Z","shell.execute_reply":"2025-07-31T05:04:40.809610Z"}},"outputs":[{"name":"stderr","text":"Preprocessing dataset: 100%|██████████| 50/50 [00:00<00:00, 365.52it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8958e171921f4efb8caa0dcff2def7ae"}},"metadata":{}},{"name":"stderr","text":"Preprocessing dataset: 100%|██████████| 50/50 [00:00<00:00, 415.07it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Flattening the indices:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d0a2947baf4e21936b1c8819154315"}},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"# Step 4: Convert training dataset to conversation format\nconverted_train_dataset = [convert_to_conversation(sample) for sample in train_dataset]\nconverted_eval_dataset = [convert_to_conversation(sample) for sample in eval_dataset]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:04:52.586961Z","iopub.execute_input":"2025-07-31T05:04:52.587202Z","iopub.status.idle":"2025-07-31T05:04:52.997011Z","shell.execute_reply.started":"2025-07-31T05:04:52.587186Z","shell.execute_reply":"2025-07-31T05:04:52.996430Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"model, tokenizer = FastVisionModel.from_pretrained(\n    \"unsloth/Qwen2-VL-7B-Instruct\",\n    load_in_4bit=True,\n    use_gradient_checkpointing=\"unsloth\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:04:55.621126Z","iopub.execute_input":"2025-07-31T05:04:55.621376Z","iopub.status.idle":"2025-07-31T05:05:11.284400Z","shell.execute_reply.started":"2025-07-31T05:04:55.621358Z","shell.execute_reply":"2025-07-31T05:05:11.283581Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.7.11: Fast Qwen2 patching. Transformers: 4.52.4.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"model = FastVisionModel.get_peft_model(\n    model,\n    finetune_vision_layers=True,\n    finetune_language_layers=True,\n    finetune_attention_modules=True,\n    finetune_mlp_modules=True,\n    r=16,\n    lora_alpha=16,\n    lora_dropout=0,\n    bias=\"none\",\n    random_state=3407,\n    use_rslora=False,\n    loftq_config=None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:05:11.286100Z","iopub.execute_input":"2025-07-31T05:05:11.286612Z","iopub.status.idle":"2025-07-31T05:05:18.628793Z","shell.execute_reply.started":"2025-07-31T05:05:11.286593Z","shell.execute_reply":"2025-07-31T05:05:18.628218Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Making `model.base_model.model.model.visual` require gradients\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"print(\"\\n=== BASELINE EVALUATION (BEFORE FINE-TUNING) ===\")\nprint(\"Evaluating on raw images...\")\nbaseline_metrics_raw, _, _ = evaluate_model(model, tokenizer, eval_dataset, image_col=\"image\", max_samples=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:05:18.629488Z","iopub.execute_input":"2025-07-31T05:05:18.629674Z","iopub.status.idle":"2025-07-31T05:14:13.322064Z","shell.execute_reply.started":"2025-07-31T05:05:18.629658Z","shell.execute_reply":"2025-07-31T05:14:13.321107Z"}},"outputs":[{"name":"stdout","text":"\n=== BASELINE EVALUATION (BEFORE FINE-TUNING) ===\nEvaluating on raw images...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 4-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"print(\"Evaluating on preprocessed images...\")\nbaseline_metrics_preprocessed, _, _ = evaluate_model(model, tokenizer, eval_dataset, image_col=\"preprocessed_image\", max_samples=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:14:13.323473Z","iopub.execute_input":"2025-07-31T05:14:13.323696Z","iopub.status.idle":"2025-07-31T05:21:22.037713Z","shell.execute_reply.started":"2025-07-31T05:14:13.323672Z","shell.execute_reply":"2025-07-31T05:21:22.036879Z"}},"outputs":[{"name":"stdout","text":"Evaluating on preprocessed images...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 2-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 3-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 4-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"print(\"\\n=== BASELINE RESULTS ===\")\nprint(\"Metric               | Raw Images | Preprocessed Images | Difference\")\nprint(\"---------------------|------------|---------------------|-----------\")\nfor metric in baseline_metrics_raw.keys():\n    raw_val = baseline_metrics_raw[metric]\n    pre_val = baseline_metrics_preprocessed[metric]\n    diff = pre_val - raw_val if isinstance(raw_val, float) else \"-\"\n    print(f\"{metric:20s} | {raw_val:.4f}      | {pre_val:.4f}            | {diff:+.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:21:22.038786Z","iopub.execute_input":"2025-07-31T05:21:22.039117Z","iopub.status.idle":"2025-07-31T05:21:22.069781Z","shell.execute_reply.started":"2025-07-31T05:21:22.039092Z","shell.execute_reply":"2025-07-31T05:21:22.068910Z"}},"outputs":[{"name":"stdout","text":"\n=== BASELINE RESULTS ===\nMetric               | Raw Images | Preprocessed Images | Difference\n---------------------|------------|---------------------|-----------\nexact_match_accuracy | 0.0000      | 0.0000            | +0.0000\naverage_bleu         | 0.6916      | 0.0001            | -0.6914\nmedian_bleu          | 0.7729      | 0.0000            | -0.7729\nstd_bleu             | 0.2448      | 0.0010            | -0.2439\naverage_edit_distance | 31.3000      | 157.3200            | +126.0200\nmedian_edit_distance | 20.5000      | 161.5000            | +141.0000\nstd_edit_distance    | 34.6192      | 55.2885            | +20.6693\ncompilation_success_rate | 0.0000      | 0.0000            | +0.0000\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3102761467.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpre_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_metrics_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mraw_val\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{metric:20s} | {raw_val:.4f}      | {pre_val:.4f}            | {diff:+.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: Unknown format code 'f' for object of type 'str'"],"ename":"ValueError","evalue":"Unknown format code 'f' for object of type 'str'","output_type":"error"}],"execution_count":60},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}