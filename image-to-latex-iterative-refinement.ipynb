{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:26:54.566227Z","iopub.execute_input":"2025-07-28T23:26:54.566711Z","iopub.status.idle":"2025-07-28T23:26:54.816927Z","shell.execute_reply.started":"2025-07-28T23:26:54.566689Z","shell.execute_reply":"2025-07-28T23:26:54.816182Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%capture\n%pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n%pip install sentencepiece protobuf datasets huggingface_hub hf_transfer nltk python-Levenshtein pylatexenc matplotlib pillow\n%pip install --no-deps unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:26:54.818144Z","iopub.execute_input":"2025-07-28T23:26:54.818451Z","iopub.status.idle":"2025-07-28T23:27:11.847370Z","shell.execute_reply.started":"2025-07-28T23:26:54.818434Z","shell.execute_reply":"2025-07-28T23:27:11.846586Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom datasets import load_dataset\nimport subprocess\nimport tempfile\nimport os\nfrom transformers import TextStreamer\nfrom nltk.translate.bleu_score import sentence_bleu\nimport Levenshtein\nimport matplotlib.pyplot as plt\n\nfrom unsloth import FastVisionModel, is_bf16_supported\nfrom unsloth.trainer import UnslothVisionDataCollator\nfrom trl import SFTTrainer, SFTConfig\n\nimport nltk\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:27:11.848344Z","iopub.execute_input":"2025-07-28T23:27:11.848631Z","iopub.status.idle":"2025-07-28T23:27:50.944844Z","shell.execute_reply.started":"2025-07-28T23:27:11.848607Z","shell.execute_reply":"2025-07-28T23:27:50.944127Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1727577034.py:12: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n\nPlease restructure your imports with 'import unsloth' at the top of your file.\n  from unsloth import FastVisionModel, is_bf16_supported\n","output_type":"stream"},{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-07-28 23:27:25.189401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753745245.396305      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753745245.458786      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Load Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"model, tokenizer = FastVisionModel.from_pretrained(\n    \"unsloth/Qwen2-VL-7B-Instruct\",\n    load_in_4bit=True,\n    use_gradient_checkpointing=\"unsloth\"\n)\n\nmodel = FastVisionModel.get_peft_model(\n    model,\n    finetune_vision_layers=True,\n    finetune_language_layers=True,\n    finetune_attention_modules=True,\n    finetune_mlp_modules=True,\n\n    r=16,\n    lora_alpha=16,\n    lora_dropout=0,\n    bias=\"none\",\n    random_state=3407,\n    use_rslora=False,\n    loftq_config=None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:27:50.946294Z","iopub.execute_input":"2025-07-28T23:27:50.946507Z","iopub.status.idle":"2025-07-28T23:28:36.713609Z","shell.execute_reply.started":"2025-07-28T23:27:50.946490Z","shell.execute_reply":"2025-07-28T23:28:36.713036Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.7.8: Fast Qwen2_Vl patching. Transformers: 4.52.4.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.85G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a1eae9d9cb542529aec0c8c85effad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f789728bc4408abb1cfe18305655f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/572 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc415d80917e4375979adf414ca74780"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa26ad96389e40dd90c9f6760a5de144"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc9d539cdc384850b81997087c98b170"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d62b72da6a4eda9d271dc7f3398f5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fd42f8b29594cac8b08378794ad8928"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/392 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b32f73b37a62418e9263b59aa8e5f7d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de2a0d2dfd6b47928fa2abbd53eb9a66"}},"metadata":{}},{"name":"stderr","text":"You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"chat_template.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7026fb5adce4460094fccf964ffeeec7"}},"metadata":{}},{"name":"stdout","text":"Unsloth: Making `model.base_model.model.model.visual` require gradients\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"unsloth/Latex_OCR\", split=\"train\")\nsplit_data = dataset.train_test_split(test_size=0.2, seed=42)\ntrain_dataset = split_data[\"train\"]\ntemp_dataset = split_data[\"test\"]\neval_test_split = temp_dataset.train_test_split(test_size=0.5, seed=42)\neval_dataset = eval_test_split[\"train\"]\ntest_dataset = eval_test_split[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:28:36.714295Z","iopub.execute_input":"2025-07-28T23:28:36.714481Z","iopub.status.idle":"2025-07-28T23:28:41.989310Z","shell.execute_reply.started":"2025-07-28T23:28:36.714465Z","shell.execute_reply":"2025-07-28T23:28:41.988730Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/519 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c4fd4278fc40fb813fac0bc8c9b7b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/344M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8649b3469382427ebe4886cb1235001f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/38.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"110e8f489ebf4615bb50b55defc7cf02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/68686 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ce5294bdd8241098106a099f609b374"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7632 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50c6dbc92a94417fa457999382656f70"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"print(f\"Train samples: {len(train_dataset)}\")\nprint(f\"Eval samples: {len(eval_dataset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:28:41.990045Z","iopub.execute_input":"2025-07-28T23:28:41.990297Z","iopub.status.idle":"2025-07-28T23:28:41.994655Z","shell.execute_reply.started":"2025-07-28T23:28:41.990278Z","shell.execute_reply":"2025-07-28T23:28:41.994109Z"}},"outputs":[{"name":"stdout","text":"Train samples: 54948\nEval samples: 6869\nTest samples: 6869\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Convert samples to conversation format","metadata":{}},{"cell_type":"code","source":"def convert_to_conversation(sample):\n    conversation = [\n        {\"role\": \"user\",\n         \"content\": [\n             {\"type\": \"text\", \"text\": \"Write the LaTeX representation for this image.\"},\n             {\"type\": \"image\", \"image\": sample[\"image\"]}\n         ]},\n        {\"role\": \"assistant\",\n         \"content\": [\n             {\"type\": \"text\", \"text\": sample[\"text\"]}\n         ]}\n    ]\n    return {\"messages\": conversation}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:28:41.995439Z","iopub.execute_input":"2025-07-28T23:28:41.995714Z","iopub.status.idle":"2025-07-28T23:28:42.008695Z","shell.execute_reply.started":"2025-07-28T23:28:41.995690Z","shell.execute_reply":"2025-07-28T23:28:42.007935Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"converted_train_dataset = [convert_to_conversation(sample) for sample in train_dataset]\nconverted_eval_dataset = [convert_to_conversation(sample) for sample in eval_dataset]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:28:42.009681Z","iopub.execute_input":"2025-07-28T23:28:42.009951Z","iopub.status.idle":"2025-07-28T23:29:05.819402Z","shell.execute_reply.started":"2025-07-28T23:28:42.009928Z","shell.execute_reply":"2025-07-28T23:29:05.818608Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Post-correction for unmatched braces (simple heuristic)","metadata":{}},{"cell_type":"code","source":"def simple_post_correct(latex_code):\n    stack = []\n    corrected = []\n    for c in latex_code:\n        if c == '{':\n            stack.append(c)\n        corrected.append(c)\n        if c == '}' and stack:\n            stack.pop()\n    corrected.extend('}' * len(stack))\n    return ''.join(corrected)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:05.820303Z","iopub.execute_input":"2025-07-28T23:29:05.820571Z","iopub.status.idle":"2025-07-28T23:29:05.825099Z","shell.execute_reply.started":"2025-07-28T23:29:05.820546Z","shell.execute_reply":"2025-07-28T23:29:05.824209Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## LaTeX compilation check","metadata":{}},{"cell_type":"code","source":"def check_latex_compilation(latex_code):\n    latex_document = f\"\"\"\n    \\\\documentclass{{article}}\n    \\\\usepackage{{amsmath, amssymb, amsfonts}}\n    \\\\begin{{document}}\n    $${latex_code}$$\n    \\\\end{{document}}\n    \"\"\"\n    try:\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.tex', delete=False) as f:\n            f.write(latex_document)\n            tex_file = f.name\n\n        result = subprocess.run(\n            ['pdflatex', '-interaction=nonstopmode', tex_file],\n            capture_output=True,\n            timeout=10,\n            cwd='/tmp'\n        )\n        base_name = tex_file[:-4]\n        for ext in ['.tex', '.pdf', '.log', '.aux']:\n            try:\n                os.unlink(base_name + ext)\n            except:\n                pass\n        return result.returncode == 0\n    except Exception:\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:05.827651Z","iopub.execute_input":"2025-07-28T23:29:05.827930Z","iopub.status.idle":"2025-07-28T23:29:05.837616Z","shell.execute_reply.started":"2025-07-28T23:29:05.827910Z","shell.execute_reply":"2025-07-28T23:29:05.836795Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Eval Metrics","metadata":{}},{"cell_type":"code","source":"def exact_match_accuracy(predictions, targets):\n    matches = [pred.strip() == target.strip() for pred, target in zip(predictions, targets)]\n    return np.mean(matches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:05.838385Z","iopub.execute_input":"2025-07-28T23:29:05.838588Z","iopub.status.idle":"2025-07-28T23:29:05.850366Z","shell.execute_reply.started":"2025-07-28T23:29:05.838568Z","shell.execute_reply":"2025-07-28T23:29:05.849673Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def calculate_bleu_scores(predictions, targets):\n    bleu_scores = []\n    for pred, target in zip(predictions, targets):\n        pred_tokens = pred.strip().split()\n        target_tokens = target.strip().split()\n        if len(target_tokens) == 0:\n            bleu_scores.append(0.0)\n        else:\n            try:\n                score = sentence_bleu([target_tokens], pred_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n                bleu_scores.append(score)\n            except:\n                bleu_scores.append(0.0)\n    return bleu_scores\n\ndef calculate_edit_distances(predictions, targets):\n    distances = []\n    for pred, target in zip(predictions, targets):\n        distance = Levenshtein.distance(pred.strip(), target.strip())\n        distances.append(distance)\n    return distances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:05.851202Z","iopub.execute_input":"2025-07-28T23:29:05.851577Z","iopub.status.idle":"2025-07-28T23:29:05.861720Z","shell.execute_reply.started":"2025-07-28T23:29:05.851554Z","shell.execute_reply":"2025-07-28T23:29:05.861108Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def compilation_success_rate(predictions):\n    success_count = sum(check_latex_compilation(pred) for pred in predictions)\n    return success_count / len(predictions) if len(predictions) > 0 else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:05.862452Z","iopub.execute_input":"2025-07-28T23:29:05.862716Z","iopub.status.idle":"2025-07-28T23:29:05.875434Z","shell.execute_reply.started":"2025-07-28T23:29:05.862695Z","shell.execute_reply":"2025-07-28T23:29:05.874732Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Iterative refinement prediction","metadata":{}},{"cell_type":"code","source":"def iterative_refine_predict(model, tokenizer, image, num_iterations=3):\n    \"\"\"\n    Runs the model multiple times, feeding back previous prediction as prompt for refinement.\n    \"\"\"\n    model.eval()\n    device = next(model.parameters()).device\n    instruction = \"Write the LaTeX representation for this image.\"\n\n    # Initial messages: no previous output\n    prev_output = None\n    for iteration in range(num_iterations):\n        messages = [\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"text\", \"text\": instruction},\n                {\"type\": \"image\", \"image\": image}\n            ]}\n        ]\n\n        # Inject previous output from last iteration as assistant message if available\n        if prev_output is not None:\n            messages.append({\n                \"role\": \"assistant\", \"content\": [\n                    {\"type\": \"text\", \"text\": prev_output}\n                ]\n            })\n\n        # Prepare input text with chat template\n        input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n\n        inputs = tokenizer(\n            image, input_text,\n            add_special_tokens=False,\n            return_tensors=\"pt\",\n        ).to(device)\n\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_new_tokens=128,\n                temperature=0.1,\n                pad_token_id=tokenizer.eos_token_id,\n                do_sample=False,  # deterministic for refinement\n                use_cache=True,\n            )\n\n        # Decode newly generated tokens (skip input tokens)\n        generated_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n        pred = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n        # Post-correct after each iteration\n        pred = simple_post_correct(pred)\n\n        prev_output = pred\n\n    return prev_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:05.876216Z","iopub.execute_input":"2025-07-28T23:29:05.876487Z","iopub.status.idle":"2025-07-28T23:29:05.889902Z","shell.execute_reply.started":"2025-07-28T23:29:05.876462Z","shell.execute_reply":"2025-07-28T23:29:05.889183Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Evaluate model with iterative refinement","metadata":{}},{"cell_type":"code","source":"def evaluate_model_with_refinement(model, tokenizer, eval_dataset, max_samples=None):\n    model.eval()\n    predictions = []\n    targets = []\n\n    samples_to_eval = eval_dataset if max_samples is None else eval_dataset.select(range(min(max_samples, len(eval_dataset))))\n    print(f\"Evaluating on {len(samples_to_eval)} samples with iterative refinement...\")\n\n    for i, sample in enumerate(samples_to_eval):\n        if i % 10 == 0:\n            print(f\"Processing sample {i+1}/{len(samples_to_eval)}\")\n\n        pred = iterative_refine_predict(model, tokenizer, sample[\"image\"], num_iterations=3)\n        predictions.append(pred)\n        targets.append(sample[\"text\"])\n\n    exact_match = exact_match_accuracy(predictions, targets)\n    bleu_scores = calculate_bleu_scores(predictions, targets)\n    edit_distances = calculate_edit_distances(predictions, targets)\n    compile_rate = compilation_success_rate(predictions)\n\n    metrics = {\n        \"exact_match_accuracy\": exact_match,\n        \"average_bleu\": np.mean(bleu_scores),\n        \"median_bleu\": np.median(bleu_scores),\n        \"std_bleu\": np.std(bleu_scores),\n        \"average_edit_distance\": np.mean(edit_distances),\n        \"median_edit_distance\": np.median(edit_distances),\n        \"std_edit_distance\": np.std(edit_distances),\n        \"compilation_success_rate\": compile_rate,\n        \"num_samples\": len(predictions)\n    }\n    return metrics, predictions, targets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:05.890618Z","iopub.execute_input":"2025-07-28T23:29:05.890955Z","iopub.status.idle":"2025-07-28T23:29:05.903248Z","shell.execute_reply.started":"2025-07-28T23:29:05.890932Z","shell.execute_reply":"2025-07-28T23:29:05.902631Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Trainer","metadata":{}},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    data_collator=UnslothVisionDataCollator(model, tokenizer),\n    train_dataset=converted_train_dataset,\n    eval_dataset=converted_eval_dataset[:100],\n    args=SFTConfig(\n        per_device_train_batch_size=32,   # very high if GPU allows\n        per_device_eval_batch_size=32,    # matches train batch size\n        gradient_accumulation_steps=1,    # minimize if batch size is high\n        warmup_steps=5,\n        num_train_epochs=2,\n        learning_rate=2e-4,\n        fp16=not is_bf16_supported(),\n        bf16=is_bf16_supported(),\n        logging_steps=500,               # log every 500 steps\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        save_total_limit=1,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_loss\",\n        greater_is_better=False,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n        report_to=\"none\",\n        remove_unused_columns=False,\n        dataset_text_field=\"\",\n        dataset_kwargs={\"skip_prepare_dataset\": True},\n        dataset_num_proc=4,\n        max_seq_length=2048,\n        dataloader_num_workers=8,         # maximize for your CPU\n    ),\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:05.904011Z","iopub.execute_input":"2025-07-28T23:29:05.904237Z","iopub.status.idle":"2025-07-28T23:29:06.316051Z","shell.execute_reply.started":"2025-07-28T23:29:05.904218Z","shell.execute_reply":"2025-07-28T23:29:06.315260Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Model does not have a default image size - using 512\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(\"Starting training without augmentation...\")\ntrainer.train()\nprint(\"Training completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:06.316962Z","iopub.execute_input":"2025-07-28T23:29:06.317685Z"}},"outputs":[{"name":"stdout","text":"Starting training without augmentation...\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 54,948 | Num Epochs = 2 | Total steps = 1,718\nO^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n \"-____-\"     Trainable parameters = 50,855,936 of 8,342,231,552 (0.61% trained)\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 54,948 | Num Epochs = 2 | Total steps = 3,436\nO^O/ \\_/ \\    Batch size per device = 32 | Gradient accumulation steps = 1\n\\        /    Data Parallel GPUs = 1 | Total batch size (32 x 1 x 1) = 32\n \"-____-\"     Trainable parameters = 50,855,936 of 8,342,231,552 (0.61% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8' max='3436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   8/3436 02:20 < 22:20:14, 0.04 it/s, Epoch 0.00/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation Begins","metadata":{}},{"cell_type":"code","source":"print(\"\\nEvaluating on validation set with iterative refinement...\")\nval_metrics, val_preds, val_tgts = evaluate_model_with_refinement(model, tokenizer, eval_dataset, max_samples=100)\nfor k,v in val_metrics.items():\n    if isinstance(v, float):\n        print(f\"{k}: {v:.4f}\")\n    else:\n        print(f\"{k}: {v}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nEvaluating on test set with iterative refinement...\")\ntest_metrics, test_preds, test_tgts = evaluate_model_with_refinement(model, tokenizer, test_dataset, max_samples=100)\nfor k,v in test_metrics.items():\n    if isinstance(v, float):\n        print(f\"{k}: {v:.4f}\")\n    else:\n        print(f\"{k}: {v}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nSample predictions (target vs prediction):\")\nfor i in range(5):\n    print(f\"Sample {i+1}:\")\n    print(f\"Target    : {test_tgts[i]}\")\n    print(f\"Prediction: {test_preds[i]}\")\n    print(f\"Match: {'âœ“' if test_tgts[i].strip() == test_preds[i].strip() else 'âœ—'}\")\n    print()\n\nprint(\"Image-to-LaTeX pipeline with iterative refinement completed!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}